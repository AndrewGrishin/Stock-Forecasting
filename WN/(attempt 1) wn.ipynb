{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from Functions.SSA import SSA\n",
    "from Functions.lions_optimizer import Lion\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# воспроизводимость\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wape(y, y_hat):\n",
    "    return np.sum(np.abs(y - y_hat)) / np.sum(np.abs(y)) * 100\n",
    "\n",
    "def mape(y, y_hat, eps= 1e-7):\n",
    "    return np.mean(np.abs((y - y_hat) / (y + eps))) * 100\n",
    "\n",
    "def series_to_X_y(series, window_size= 30):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(series) - window_size):\n",
    "        row = list(map(lambda a: a, series[i:i + window_size]))\n",
    "        X.append(np.array(row))\n",
    "        col = [series[i + window_size]]\n",
    "        y.append(np.array(col))\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MinMaxScaler():\n",
    "    def __init__(self):\n",
    "        self.min = 0\n",
    "        self.max = 1\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.min = data.min()\n",
    "        self.max = data.max()\n",
    "\n",
    "    def transform(self, data):\n",
    "        return (data - self.min) / (self.max - self.min)\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return (self.max - self.min) * data + self.min\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Min: {self.min}\\nMax: {self.max}\"\n",
    "\n",
    "class StandardScaler():\n",
    "    def __init__(self):\n",
    "        self.mean = 0\n",
    "        self.std = 1\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.mean = data.mean()\n",
    "        self.std = data.std()\n",
    "\n",
    "    def transform(self, data):\n",
    "        return (data - self.mean) / self.std\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.std * data + self.mean\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Mean: {self.mean}\\nStd: {self.std}\"\n",
    "\n",
    "class MexicanHat(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return (1 - X ** 2) * torch.exp(-1 / 2 * X ** 2)\n",
    "\n",
    "class WN(nn.Module):\n",
    "    def __init__(self, input_features, number_of_wavelons= 1):\n",
    "        super(WN, self).__init__()\n",
    "        # сдвиг\n",
    "        self.translation = torch.nn.Parameter(torch.rand([input_features, number_of_wavelons], requires_grad= True))\n",
    "        # сжатие\n",
    "        self.dilation = torch.nn.Parameter(torch.rand([input_features, number_of_wavelons], requires_grad= True))\n",
    "\n",
    "        # веса линейной части\n",
    "        self.lm_weights = torch.nn.Parameter(torch.rand(1 + input_features, requires_grad= True))\n",
    "        # веса wavelet части\n",
    "        self.wn_weights = torch.nn.Parameter(torch.rand(number_of_wavelons, requires_grad= True))\n",
    "\n",
    "        self.number_of_wavelons = number_of_wavelons\n",
    "        self.input_features = input_features\n",
    "\n",
    "        self.activation_function = MexicanHat()\n",
    "\n",
    "    def forward(self, X, device= \"cpu\"):\n",
    "        output = torch.zeros(X.shape[0]).to(device)\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            vector = X[i]\n",
    "            J = torch.concat([torch.unsqueeze(vector, dim= 1) for _ in range(self.number_of_wavelons)], dim= 1).to(device)\n",
    "            Z = (J - self.translation.to(device)) / self.dilation.to(device)\n",
    "\n",
    "            Z_new = self.activation_function(Z)\n",
    "\n",
    "            Z_new_trans = torch.t(Z_new)\n",
    "            Z_final = torch.prod(Z_new_trans, dim= 1)\n",
    "\n",
    "            wavelet_net = torch.dot(Z_final, self.wn_weights.to(device))\n",
    "            linear_net = torch.dot(torch.concat([torch.tensor([1], dtype= torch.float32).to(device), vector.to(device)]), self.lm_weights.to(device))\n",
    "            output[i] = wavelet_net + linear_net\n",
    "\n",
    "        return torch.unsqueeze(output, dim= 1)\n",
    "\n",
    "class TimeSeriesDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.X[item], self.y[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_ewma(data, window):\n",
    "\n",
    "    alpha = 2 /(window + 1.0)\n",
    "    alpha_rev = 1-alpha\n",
    "    n = data.shape[0]\n",
    "\n",
    "    pows = alpha_rev**(np.arange(n+1))\n",
    "\n",
    "    scale_arr = 1/pows[:-1]\n",
    "    offset = data[0]*pows[1:]\n",
    "    pw0 = alpha*alpha_rev**(n-1)\n",
    "\n",
    "    mult = data*pw0*scale_arr\n",
    "    cumsums = mult.cumsum()\n",
    "    out = offset + cumsums*scale_arr[::-1]\n",
    "    return out\n",
    "\n",
    "def get_all_ewma(y, alpha= 2, n= 5):\n",
    "    v = []\n",
    "    beta = 1 - alpha / (n + 1)\n",
    "\n",
    "    for i in range(1, len(y) + 1):\n",
    "        betas = (beta * np.ones(i)) ** np.arange(i)\n",
    "        addition = np.dot(betas, (y[:i])[::-1])\n",
    "        new_value = (1 - beta) * addition\n",
    "        correction = (1 - beta ** (i)) ** (-1)\n",
    "        v.append(new_value * correction)\n",
    "\n",
    "    return np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, epochs, train_data, device= \"cpu\"):\n",
    "\n",
    "    model = model.to(device)\n",
    "    best_model = None\n",
    "    best_eval_loss = torch.inf\n",
    "\n",
    "    train_loader = train_data[\"train\"]\n",
    "    val_loader = train_data[\"val\"]\n",
    "\n",
    "    epochs_bar = tqdm(range(epochs), desc= \"Epoch\")\n",
    "    for epoch in epochs_bar:\n",
    "\n",
    "        avg_train_loss = 0\n",
    "        avg_train_metric = 0\n",
    "        train_len = 0\n",
    "        standard_len = None\n",
    "\n",
    "        model.train()\n",
    "        for ind, (X_train_bt, y_train_bt) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_preds = model(X_train_bt.to(device), device= device)\n",
    "            train_loss = criterion(train_preds, y_train_bt.to(device))\n",
    "\n",
    "            # ingroup\n",
    "            avg_train_loss += train_loss.item()\n",
    "\n",
    "            if standard_len is None:\n",
    "                standard_len = X_train_bt.shape[0]\n",
    "\n",
    "            train_len += (X_train_bt.shape[0] / standard_len)\n",
    "\n",
    "            model.train()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # over group\n",
    "        avg_train_loss /= train_len\n",
    "        avg_train_metric /= train_len\n",
    "\n",
    "        avg_val_loss = 0\n",
    "        val_len = 0\n",
    "        standard_len = None\n",
    "\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for ind, (X_val_bt, y_val_bt) in enumerate(val_loader):\n",
    "                val_preds = model(X_val_bt.to(device), device= device)\n",
    "                val_loss = criterion(val_preds, y_val_bt.to(device))\n",
    "                # ingroup\n",
    "                avg_val_loss += val_loss.item()\n",
    "\n",
    "                if standard_len is None:\n",
    "                    standard_len = X_val_bt.shape[0]\n",
    "\n",
    "                val_len += (X_val_bt.shape[0] / standard_len)\n",
    "\n",
    "        # over group\n",
    "        avg_val_loss /= val_len\n",
    "\n",
    "        ans = avg_val_loss < best_eval_loss\n",
    "        if ans:\n",
    "            best_eval_loss = avg_val_loss\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(best_model, \"best_model.pt\")\n",
    "\n",
    "        epochs_bar.set_description(f\"Epoch: {epoch + 1}/{epochs} Val loss: {avg_val_loss:.5f}. Best loss: {best_eval_loss:.5f}\")\n",
    "\n",
    "def eval(model, test_loader, metric, device= \"cpu\"):\n",
    "    model = model.to(device)\n",
    "\n",
    "    answer = []\n",
    "    y = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_pbar = tqdm(enumerate(test_loader), desc= \"Batch\", total= len(test_loader), disable= True)\n",
    "        for ind, (X_test_bt, y_test_bt) in test_pbar:\n",
    "            test_pbar.set_description(f\"Test: {ind + 1}/{len(test_loader)}\")\n",
    "\n",
    "            test_preds = model(X_test_bt.to(device), device= device)\n",
    "\n",
    "            answer += list(test_preds.cpu().detach().numpy())\n",
    "            y += list(y_test_bt.cpu().detach().numpy())\n",
    "\n",
    "    return metric(np.array(y).reshape(-1), np.array(answer).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_wapes(path, country, prices_not_returns, windows_size, neurons, metrics, epochs, val_size, test_size, device, use_denoising, use_ewma):\n",
    "\n",
    "    checker = 0\n",
    "\n",
    "    result_dict = dict()\n",
    "\n",
    "    entries = os.listdir(path)\n",
    "    entries.remove(\".DS_Store\")\n",
    "\n",
    "    pbar_company = tqdm(entries)\n",
    "    for file in pbar_company:\n",
    "        pbar_company.set_description(f\"{country}: Epoch\")\n",
    "        df = pd.read_csv(path + file if path[-1] == r\"/\" else path + r\"/\" + file).dropna()\n",
    "        series = np.array(df.Open) if prices_not_returns else np.array(df.Open.pct_change())[1:]\n",
    "        series_initial = series[:]\n",
    "\n",
    "        if use_denoising:\n",
    "            _, series = SSA.multiple_stage_denoising(series, max_iter= 50)\n",
    "\n",
    "        X, _ = series_to_X_y(series, windows_size)\n",
    "        _, y = series_to_X_y(series_initial, windows_size)\n",
    "\n",
    "        if use_ewma:\n",
    "            ewmas = np.asmatrix([get_all_ewma(series_initial, 2, i) for i in range(2, 30)])\n",
    "            X = np.concatenate([X, ewmas[:, windows_size - 1:-1].T], axis= 1)\n",
    "            if checker == 0:\n",
    "                neurons[\"input_dim\"] += (X.shape[-1] - windows_size)\n",
    "                checker = 1\n",
    "\n",
    "        X = torch.from_numpy(X).to(device).to(torch.float32)\n",
    "        y = torch.from_numpy(y).to(device).to(torch.float32)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test_size, shuffle= False)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size= val_size, shuffle= False)\n",
    "\n",
    "        # скалирование\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        scaler.fit(torch.concat((X_train[0].reshape(-1, 1), y_train, y_val), dim= 0))\n",
    "\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        y_train = scaler.transform(y_train)\n",
    "        y_val = scaler.transform(y_val)\n",
    "        y_test = scaler.transform(y_test)\n",
    "        #\n",
    "\n",
    "        X_train = X_train.to(device)\n",
    "        X_val = X_val.to(device)\n",
    "        X_test = X_test.to(device)\n",
    "\n",
    "        y_train = y_train.to(device)\n",
    "        y_val = y_val.to(device)\n",
    "        y_test = y_test.to(device)\n",
    "\n",
    "        if checker == 0:\n",
    "            neurons = [windows_size] + neurons\n",
    "            checker = 1\n",
    "\n",
    "        model = WN(*neurons).to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = Lion(model.parameters(), lr= 3e-4 / 2)\n",
    "\n",
    "        #### Обучение\n",
    "        train_dataset = TimeSeriesDataSet(X_train, y_train)\n",
    "        val_dataset = TimeSeriesDataSet(X_val, y_val)\n",
    "        test_dataset = TimeSeriesDataSet(X_test, y_test)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "                batch_size= 256,\n",
    "            shuffle= False\n",
    "        )\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset,\n",
    "                batch_size= 256,\n",
    "            shuffle= False\n",
    "        )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "                batch_size= 256,\n",
    "            shuffle= False,\n",
    "        )\n",
    "\n",
    "        train_params = {\n",
    "            \"model\": model,\n",
    "            \"criterion\": criterion,\n",
    "            \"optimizer\": optimizer,\n",
    "            \"epochs\": epochs,\n",
    "            \"train_data\": {\n",
    "                \"train\": train_loader,\n",
    "                \"val\": val_loader\n",
    "            },\n",
    "            \"device\": device\n",
    "        }\n",
    "        train(**train_params)\n",
    "\n",
    "        #### Вычисление\n",
    "        model = WN(*neurons)\n",
    "        model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "\n",
    "        metrics_val = eval(model, test_loader, metrics, device= device)\n",
    "        ####\n",
    "\n",
    "        result_dict[file[:-14]] = metrics_val\n",
    "\n",
    "        print(f\"{file[:-14]}: Test error: {result_dict[file[:-14]]:.2f}%\")\n",
    "        os.remove(\"best_model.pt\")\n",
    "\n",
    "\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_us_prices = {\n",
    "    \"path\": \"../Data/American Companies\",\n",
    "    \"country\": \"US\",\n",
    "    \"prices_not_returns\": True,\n",
    "\n",
    "    \"windows_size\": 5,\n",
    "    \"neurons\": [5],\n",
    "\n",
    "    \"metrics\": wape,\n",
    "\n",
    "    \"epochs\": 500,\n",
    "    \"val_size\": 0.2,\n",
    "    \"test_size\": 0.1,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"use_denoising\": False,\n",
    "    \"use_ewma\": False\n",
    "}\n",
    "\n",
    "params_us_returns = {\n",
    "    \"path\": \"../Data/American Companies\",\n",
    "    \"country\": \"US\",\n",
    "    \"prices_not_returns\": False,\n",
    "\n",
    "    \"windows_size\": 100,\n",
    "    \"output_size\": 1,\n",
    "    \"neurons\": {\n",
    "        \"hid_dim\": 350,\n",
    "        \"num_layers\": 2,\n",
    "        \"type\": \"lstm\",\n",
    "        \"dropout\": 0.0\n",
    "    },\n",
    "\n",
    "    \"metrics\": wape,\n",
    "\n",
    "    \"epochs\": 10_000,\n",
    "    \"val_size\": 0.2,\n",
    "    \"test_size\": 0.1,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"use_denoising\": True,\n",
    "    \"use_ewma\": False\n",
    "}\n",
    "\n",
    "params_ch_prices = {\n",
    "    \"path\": \"../Data/Chinese Companies\",\n",
    "    \"country\": \"CH\",\n",
    "    \"prices_not_returns\": True,\n",
    "\n",
    "    \"windows_size\": 100,\n",
    "    \"output_size\": 1,\n",
    "    \"neurons\": {\n",
    "        \"hid_dim\": 350,\n",
    "        \"num_layers\": 2,\n",
    "        \"type\": \"gru\",\n",
    "        \"dropout\": 0.0\n",
    "    },\n",
    "\n",
    "    \"metrics\": wape,\n",
    "\n",
    "    \"epochs\": 10_000,\n",
    "    \"val_size\": 0.2,\n",
    "    \"test_size\": 0.1,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"use_denoising\": True,\n",
    "    \"use_ewma\": False\n",
    "}\n",
    "\n",
    "params_ch_returns = {\n",
    "    \"path\": \"../Data/Chinese Companies\",\n",
    "    \"country\": \"CH\",\n",
    "    \"prices_not_returns\": False,\n",
    "\n",
    "    \"windows_size\": 100,\n",
    "    \"output_size\": 1,\n",
    "    \"neurons\": {\n",
    "        \"hid_dim\": 350,\n",
    "        \"num_layers\": 2,\n",
    "        \"type\": \"gru\",\n",
    "        \"dropout\": 0.0\n",
    "    },\n",
    "\n",
    "    \"metrics\": wape,\n",
    "\n",
    "    \"epochs\": 10_000,\n",
    "    \"val_size\": 0.2,\n",
    "    \"test_size\": 0.1,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"use_denoising\": True,\n",
    "    \"use_ewma\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579cccaccb434fe68db6b08437833303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ad3a609c914e9d80820deb40da1f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMZN: Test error: 62.36%\n"
     ]
    },
    {
     "ename": "<class 'TypeError'>",
     "evalue": "WN.__init__() takes from 2 to 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result_dict_prices_us \u001b[38;5;241m=\u001b[39m \u001b[43mget_wapes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams_us_prices\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 60\u001b[0m, in \u001b[0;36mget_wapes\u001b[0;34m(path, country, prices_not_returns, windows_size, neurons, metrics, epochs, val_size, test_size, device, use_denoising, use_ewma)\u001b[0m\n\u001b[1;32m     56\u001b[0m y_test \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     58\u001b[0m neurons \u001b[38;5;241m=\u001b[39m [windows_size] \u001b[38;5;241m+\u001b[39m neurons\n\u001b[0;32m---> 60\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mWN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mneurons\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     61\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m     62\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Lion(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3e-4\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: WN.__init__() takes from 2 to 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "result_dict_prices_us = get_wapes(**params_us_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# result_dict_returns_us = get_wapes(**params_us_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# result_dict_prices_ch = get_wapes(**params_ch_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# result_dict_returns_ch = get_wapes(**params_ch_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# us_result = pd.DataFrame({\n",
    "#     \"Company\": result_dict_prices_us.keys(),\n",
    "#     \"WAPE (price)\": result_dict_prices_us.values(),\n",
    "#     \"WAPE (return)\": result_dict_returns_us.values()\n",
    "# })\n",
    "#\n",
    "# ch_result = pd.DataFrame({\n",
    "#     \"Company\": result_dict_prices_ch.keys(),\n",
    "#     \"WAPE (price)\": result_dict_prices_ch.values(),\n",
    "#     \"WAPE (return)\": result_dict_returns_ch.values()\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# us_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# round(us_result.describe(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ch_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# round(ch_result.describe(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# us_result.to_csv(\"wn_us_price.csv\", index= False)\n",
    "# ch_result.to_csv(\"wn_ch_price.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
